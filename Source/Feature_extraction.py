# Word2Vec
# Word Embeddings: Represent words as dense vectors in a continuous vector space.
# Word embeddings capture semantic relationships between
# words and can be learned from large text corpora using
# techniques like Word2Vec or GloVe.




